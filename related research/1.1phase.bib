@article{May2019,
abstract = {Background: Recordings of gamers interacting with video games have become a mainstay of online video-sharing communities such as YouTube. Sometimes called Let's Play videos, those recordings include content relatable to usability testing sessions and potentially illustrate basic think-aloud protocols. Literature review: Research regarding think-aloud protocols indicates that the use of video to review concurrent user commentary is a valid usability testing technique, including sessions that include little to no tester instruction or intervention. Evaluation using a heuristic created for the studied interface can support this type of usability testing. Research questions: 1. Based on a heuristic created from video game usability research, do Let's Play videos provide content representative of think-aloud protocols regarding usability of the games played? 2. Are relevant Let's Play videos potentially useful tools for illustrating think-aloud protocols to students unfamiliar with this type of usability testing? Methods: After reviewing research concerning video game heuristics to create a common set of guidelines, the author selected and reviewed five YouTube videos, gathering and coding information related to the heuristic. Results: The recordings were found to contain relevant information regarding video game usability based on the criteria developed from the literature, specifically considering verbalizations relative to think-aloud protocols. Conclusion: Because these gaming videos contain commentary measurable against a research-based heuristic for game usability, they could be used as an additional method to introduce think-aloud protocols to usability students.},
author = {May, Jamie},
doi = {10.1109/TPC.2018.2867130},
issn = {03611434},
journal = {IEEE Transactions on Professional Communication},
keywords = {Heuristic analysis,Let's Play (LP) videos,think-aloud protocols (TAPs),usability testing,video games},
month = {mar},
number = {1},
pages = {94--103},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{YouTube Gamers and Think-Aloud Protocols: Introducing Usability Testing}},
volume = {62},
year = {2019}
}
@inproceedings{Drew2018,
abstract = {The System Usability Scale (SUS) is widely used as a quick method for measuring usability; however, past research showed there is only a weak relationship between SUS scores and one behavioral usability measure, and alternatively, SUS corresponds more strongly with user preference. This suggests that the underlying constructs of the SUS may not be well understood. In this study, participants were asked to think aloud while completing a usability test and filling out the SUS. Correlations showed no relationship between behavioral performance and SUS scores. Instead, a relationship was observed between SUS scores and perceived success. Furthermore, participants described a variety of reasons for selecting their SUS responses that were unrelated to the usability of the system, which we have termed rationalizations. This suggests that the SUS is constructed of a combination of experiential components, including attitudinal perceptions. Consequently, SUS scores may be more helpful as a tool for comparison (between competitors, iterations, etc.,) or when used in conjunction with formative usability testing methods to provide a holistic view of real and perceived user experience.},
author = {Drew, Mandy R. and Falcone, Brooke and Baccus, Wendy L.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-91797-9_25},
isbn = {9783319917962},
issn = {16113349},
keywords = {SUS,System Usability Scale,Think-aloud protocol,Usability testing,User experience},
pages = {356--366},
publisher = {Springer Verlag},
title = {{What does the system usability scale (SUS) measure?: Validation using think aloud verbalization and behavioral metrics}},
volume = {10918 LNCS},
year = {2018}
}
@article{Fan2020a,
abstract = {Think-aloud protocols are widely used by user experience (UX) practitioners in usability testing to uncover issues in user interface design. It is often arduous to analyze large amounts of recorded think-aloud sessions and few UX practitioners have an opportunity to get a second perspective during their analysis due to time and resource constraints. Inspired by the recent research that shows subtle verbalization and speech patterns tend to occur when users encounter usability problems, we take the first step to design and evaluate an intelligent visual analytics tool that leverages such patterns to identify usability problem encounters and present them to UX practitioners to assist their analysis. We first conducted and recorded think-aloud sessions, and then extracted textual and acoustic features from the recordings and trained machine learning (ML) models to detect problem encounters. Next, we iteratively designed and developed a visual analytics tool, VisTA, which enables dynamic investigation of think-aloud sessions with a timeline visualization of ML predictions and input features. We conducted a between-subjects laboratory study to compare three conditions, i.e., VisTA, VisTASimple (no visualization of the ML's input features), and Baseline (no ML information at all), with 30 UX professionals. The findings show that UX professionals identified more problem encounters when using VisTA than Baseline by leveraging the problem visualization as an overview, anticipations, and anchors as well as the feature visualization as a means to understand what ML considers and omits. Our findings also provide insights into how they treated ML, dealt with (dis)agreement with ML, and reviewed the videos (i.e., play, pause, and rewind).},
author = {Fan, Mingming and Wu, Ke and Zhao, Jian and Li, Yue and Wei, Winter and Truong, Khai N.},
doi = {10.1109/TVCG.2019.2934797},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Think-aloud,UX practices,machine intelligence,session review behavior,usability problems,user study,visual analytics},
month = {jan},
number = {1},
pages = {343--352},
pmid = {31443019},
publisher = {IEEE Computer Society},
title = {{VisTA: Integrating Machine Intelligence with Visualization to Support the Investigation of Think-Aloud Sessions}},
volume = {26},
year = {2020}
}
@article{Betz2021,
author = {Betz, Gregor},
journal = {CoRR},
title = {{Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2.}},
url = {https://arxiv.org/abs/2103.13033},
volume = {abs/2103.1},
year = {2021}
}
@inproceedings{Gopstein2020,
abstract = {Atoms of confusion are small patterns of code that have been empirically validated to be difficult to hand-evaluate by programmers. Previous research focused on defining and quantifying this phenomenon, but not on explaining or critiquing it. In this work, we address core omissions to the body of work on atoms of confusion, focusing on the 'how' and 'why' of programmer misunderstanding. We performed a think-aloud study in which we observed programmers, both professionals and students, as they hand-evaluated confusing code. We performed a qualitative analysis of the data and found several surprising results, which explain previous results, outline avenues of further research, and suggest improvements of the research methodology. A notable observation is that correct hand-evaluations do not imply understanding, and incorrect evaluations not misunderstanding. We believe this and other observations may be used to improve future studies and models of program comprehension. We argue that thinking of confusion as an atomic construct may pose challenges to formulating new candidates for atoms of confusion. Ultimately, we question whether hand-evaluation correctness is, itself, a sufficient instrument to study program comprehension.},
author = {Gopstein, Dan and Fayard, Anne Laure and Apel, Sven and Cappos, Justin},
booktitle = {ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
doi = {10.1145/3368089.3409714},
isbn = {9781450370431},
keywords = {Atoms of Confusion,Program Understanding,Think-Aloud Study},
month = {nov},
pages = {605--616},
publisher = {Association for Computing Machinery, Inc},
title = {{Thinking aloud about confusing code: A qualitative investigation of program comprehension and atoms of confusion}},
year = {2020}
}
@book{Alhadreti2016,
author = {Alhadreti, Obead},
title = {{Thinking about thinking aloud: an investigation of think-aloud methods in usability testing.}},
url = {http://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.699593},
year = {2016}
}
@article{McDonald2020,
abstract = {This study compared the results of a usability inspection conducted under two separate conditions: An explicit concurrent think-aloud that required explanations and silent working. 12 student analysts inspected two travel websites thinking-aloud and working in silence to produce a set of problem predictions. Overall, the silent working condition produced more initial predictions, but the think-aloud condition yielded a greater proportion of accurate predictions as revealed by falsification testing. The analysts used a range of problem discovery methods with system searching being favoured by the silent working condition and the more active, goal playing discovery method in the think-aloud condition. Thinking-aloud was also associated with a broader spread of knowledge resources.},
author = {McDonald, Sharon and Cockton, Gilbert and Irons, Alastair},
doi = {10.1145/3397876},
issn = {25730142},
journal = {Proceedings of the ACM on Human-Computer Interaction},
keywords = {evaluation resources,heuristic evaluation,think-aloud,usability inspection},
month = {jun},
number = {EICS},
pages = {88:1--88:22},
publisher = {Association for Computing Machinery},
title = {{The Impact of Thinking-Aloud on Usability Inspection}},
volume = {4},
year = {2020}
}
@article{Salmeron2017,
abstract = {When students solve problems on the Internet, they have to find a balance between quickly scanning large sections of information in web pages and deeply processing those that are relevant for the task. We studied how high school students articulate scanning and deeper processing of information while answering questions using a Wikipedia document, and how their reading comprehension skills and the question type interact with these processes. By analyzing retrospective think-aloud protocols and eye-tracking measures, we found that scanning of information led to poor hypertext comprehension, while deep processing of information produced better performance, especially in location questions. This relationship between scanning, deep processing, and performance was qualified by reading comprehension skills in an unexpected way: Scanning led to lower performance especially for good comprehenders, while the positive effect of deep processing was independent of reading comprehension skills. We discussed the results in light of our current knowledge of Internet problem solving.},
author = {Salmer{\'{o}}n, L. and Naumann, J. and Garc{\'{i}}a, V. and Fajardo, I.},
doi = {10.1111/jcal.12152},
issn = {13652729},
journal = {Journal of Computer Assisted Learning},
keywords = {Internet problem solving,cued retrospective think aloud,eye tracking,reading comprehension},
month = {jun},
number = {3},
pages = {222--233},
publisher = {Blackwell Publishing Ltd},
title = {{Scanning and deep processing of information in hypertext: an eye tracking and cued retrospective think-aloud study}},
volume = {33},
year = {2017}
}
@article{Siddiq2017,
abstract = {Collaborative problem solving (ColPS) skills are considered crucial to succeed in work, education, and life in a knowledge-rich society. Nevertheless, research on the assessment of ColPS is at its initial stage; specifically, assessments of synchronous student-student ColPS in digital environments have been scarcely investigated, and there is an ample need for valid and reliable assessments to measure ColPS. The present study attempts to fill this gap by proposing a novel ColPS task and investigating students' ColPS skills with the help of think-aloud protocols while they were taking an online performance-based test. The task was developed on the basis of a ColPS framework, and principles emphasized in the research literature on students' interaction, collaboration, and problem solving were implemented. A real-world problem mimicking a common teaching and learning situation formed the context of this task. The empirical evidence obtained from the think-aloud protocols of eleven Norwegian students displayed the strengths and weaknesses of the task, and strengthened the feasibility to assess ColPS. Implications for the future design of ColPS tasks are discussed.},
author = {Siddiq, Fazilat and Scherer, Ronny},
doi = {10.1016/j.chb.2017.08.007},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Assessment and teaching of 21st century skills (AT,Collaborative problem solving,Computer-based assessment,Educational technology,Think-aloud protocol},
month = {nov},
pages = {509--525},
publisher = {Elsevier Ltd},
title = {{Revealing the processes of students' interaction with a novel collaborative problem solving task: An in-depth analysis of think-aloud protocols}},
volume = {76},
year = {2017}
}
@inproceedings{Alhadreti2018,
abstract = {This paper presents the results of a study that compared three think-aloud methods: concurrent think-aloud, retrospective think-aloud, and a hybrid method. The three methods were compared through an evaluation of a library website, which involved four points of comparison: task performance, participants' experiences, usability problems discovered, and the cost of employing the methods. The results revealed that the concurrent method outperformed both the retrospective and the hybrid methods in facilitating successful usability testing. It detected higher numbers of usability problems than the retrospective method, and produced output comparable to that of the hybrid method. The method received average to positive ratings from its users, and no reactivity was observed. Lastly, this method required much less time on the evaluator's part than did the other two methods, which involved double the testing and analysis time.},
author = {Alhadreti, Obead and Mayhew, Pam},
booktitle = {Conference on Human Factors in Computing Systems - Proceedings},
doi = {10.1145/3173574.3173618},
isbn = {9781450356206},
keywords = {Human-computer interaction,Think-aloud protocols,Usability testing,User experiences,User studies},
month = {apr},
pages = {44},
publisher = {Association for Computing Machinery},
title = {{Rethinking thinking aloud: A comparison of three think-aloud protocols}},
volume = {2018-April},
year = {2018}
}
@inproceedings{Jayathirtha2021,
abstract = {Comprehending programs is key to learning programming. Previous studies highlight novices' naive approaches to comprehending the structural, functional, and behavioral aspects of programs. And yet, with the majority of them examining on-screen programming environments, we barely know about program comprehension within physical computing-a common K-12 programming context. In this study, we qualitatively analyzed think-aloud interview videos of 22 high school students individually comprehending a given text-based Arduino program while interacting with its corresponding functional physical artifact to answer two questions: 1) How do novices comprehend the given text-based Arduino pro-gram? And, 2) What role does the physical artifact play in program comprehension? We found that novices mostly approached the program bottom-up, initially comprehending structural and later functional aspects, along different granularities. The artifact provided two distinct modes of engagement, active and interactive, that supported the program's structural and functional comprehension. However, behavioral comprehension i.e. understanding program execution leading to the observed outcome was inaccessible to many. Our findings extend program comprehension literature in two ways: (a) it provides one of the very few accounts of high school students' code comprehension in a physical computing context , and, (b) it highlights the mediating role of physical artifacts in program comprehension. Further, they point directions for future pedagogical and tool designs within physical computing to better support students' distributed program comprehension. CCS CONCEPTS • Applied computing → Interactive learning environments.},
author = {Jayathirtha, Gayithri and Kafai, Yasmin B.},
booktitle = {ITiCSE '21: Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V. 1},
doi = {10.1145/3430665.3456371},
file = {:C\:/Users/geryxyz/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jayathirtha, Kafai - 2021 - Program Comprehension with Physical Computing A Structure, Function, and Behavior Analysis of Think-Alouds w.pdf:pdf;::},
keywords = {electronic textiles,physical computing,program comprehension,secondary education},
month = {jun},
number = {1},
pages = {143--149},
publisher = {Association for Computing Machinery (ACM)},
title = {{Program Comprehension with Physical Computing: A Structure, Function, and Behavior Analysis of Think-Alouds with High School Students}},
url = {https://doi.org/10.1145/3430665.3456371},
year = {2021}
}
@inproceedings{Jayathirtha2020,
abstract = {Much attention has focused on student learning while making physical computational artifacts such as robots or electronic textiles, but little is known about how students engage with the hardware and software debugging issues that often arise. In order to better understand students' debugging strategies and practices, we conducted and video-recorded eight think-aloud sessions ($\sim$45 minutes each) of high school student pairs debugging electronic textiles projects with researcher-designed programming and circuitry/crafting bugs. We analyzed each video to understand pairs' debugging strategies and practices in navigating the multi-representational problem space. Our findings reveal the importance of employing system-level strategies while debugging physical computing systems, and of coordinating between various components of physical computing systems, for instance between the physical artifact, representations on paper, and the onscreen programming environment. We discuss the implications of our findings for future research and designing instruction and tools for learning with and debugging physical computing systems.},
author = {Jayathirtha, Gayithri and Fields, Deborah and Kafa, Yasmin},
booktitle = {Computer-Supported Collaborative Learning Conference, CSCL},
isbn = {9781732467262},
issn = {15734552},
keywords = {Debugging,Electronic textiles,High school computing learning,Physical computing,Think-aloud protocol},
pages = {1047--1054},
title = {{Pair debugging of electronic textiles projects: Analyzing think-aloud protocols for high school students' strategies and practices while problem solving}},
url = {https://repository.isls.org/handle/1/6292},
volume = {2},
year = {2020}
}
@inproceedings{Izu2017,
abstract = {Abstraction is a core skill for both programming and problem solving, however it is also a challenge for many students to develop a correct understanding of abstract concepts, such as program behaviour, which causes them to struggle with both introductory and advanced programming courses. Thus, evaluating students' ability to reason about programs should be an important topic for CS education. We use a think-aloud study to record and analyse the strategies students apply to reason about program behaviour within the context of reversibility. Reversibility is a property of a program or function that indicates it could be brought back to its original state. Reasoning about reversibility requires students to have a mental model of the state, thus they should reason about program behaviour as a whole, compared with reasoning about concrete cases using testing and tracing. We have identified four strategies used by students to complete the reversibility task, which we have named as algorithm decomposition, input analysis, abstraction and inductive testing. Although 70% of students successful identified reversibility in 2 of the 3 exercises, most students fail to correctly reason about reversibility in an exercise involving a seemingly simple conditional statement.},
author = {Izu, Cruz and Pope, Cheryl and Weerasinghe, Amali},
booktitle = {Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE},
doi = {10.1145/3059009.3059036},
isbn = {9781450347044},
issn = {1942647X},
keywords = {Programming,Reasoning,Reversibility,State,Think-aloud},
month = {jun},
pages = {305--310},
publisher = {Association for Computing Machinery},
title = {{On the ability to reason about program behaviour: A think-aloud study}},
volume = {Part F1286},
year = {2017}
}
@inproceedings{Fan2021,
abstract = {Subtle patterns in users' think-aloud (TA) verbalizations and speech features are shown to be telltale signs of User Experience (UX) problems. However, such patterns were uncovered among young adults. Whether such patterns apply for older adults remains unknown. We conducted TA usability testing with older adults using physical and digital products. We analyzed their verbalizations, extracted speech features, identifed UX problems, and uncovered the patterns that indicate UX problems. Our results show that when older adults encounter problems, their verbalizations tend to include observations (remarks), negations, question words and words with negative sentiments; and their voices tend to include high loudness, high pitch and high speech rate. We compare these subtle patterns with those of young adults uncovered in recent studies and discuss the implications of these patterns for the design of Human-AI collaborative UX analysis tools to better pinpoint UX problems.},
author = {Fan, Mingming and Zhao, Qiwen and Tibdewal, Vinita},
booktitle = {Conference on Human Factors in Computing Systems - Proceedings},
doi = {10.1145/3411764.3445680},
isbn = {9781450380966},
keywords = {Ai-assisted ux analysis,Elderly,Human-ai collaboration for ux analysis,Older adults,Remote usability testing,Seniors,Speech features,Think-aloud,Usability testing,Ux problems,Verbalization},
month = {may},
pages = {358:1--358:13},
publisher = {Association for Computing Machinery},
title = {{Older adults' think-aloud verbalizations and speech features for identifying user experience problems}},
year = {2021}
}
@article{Parizi2018,
author = {Parizi, Reza M.},
journal = {CoRR},
title = {{Microservices as an Evolutionary Architecture of Component-Based Development: A Think-aloud Study.}},
url = {http://arxiv.org/abs/1805.11757},
volume = {abs/1805.1},
year = {2018}
}
@article{Mcdonald2016,
abstract = {We report the results of a study comparing two concurrent think-aloud approaches for usability testing: the classic think-aloud (CTA) and an interactive think-aloud (ITA). The think-alouds were compared in respect of task performance and usability problem data. We also analyse the utility of the interventions used within the ITA in eliciting useful participant utterances. The most useful interventions were those focused on seeking explanations and opinions; these generated more utterances about user difficulties. Requests for clarifications, particularly about actions, resulted in fewer useful utterances: participants responded with simple procedural descriptions. In comparing the CTA and ITA, we found no differences in the number of successfully completed tasks, but the ITA did elongate the test session. The ITA led to the detection of more usability problems overall, and a greater number of causal explanations. However, the ITA produced more low-severity problems than the CTA.},
author = {Mcdonald, Sharon and Zhao, Tingting and Edwards, Helen M.},
doi = {10.1093/iwc/iwv014},
issn = {09535438},
journal = {Interacting with Computers},
keywords = {classic think-aloud,concurrent think-aloud,interactive think-aloud,usability evaluation,usability testing,user studies},
month = {may},
number = {3},
pages = {387--403},
publisher = {Oxford University Press},
title = {{Look who's talking: Evaluating the utility of interventions during an interactive think-aloud}},
volume = {28},
year = {2016}
}
@article{Prokop2020,
abstract = {Simulations and games bring the possibility to research complex processes of managerial decision-making. However, this modern field requires adequate methodological procedures. Many authors recommend the use of a combination of concurrent think-aloud (CTA) or retrospective think-aloud (RTA) with eye-tracking to investigate cognitive processes such as decision-making. Nevertheless, previous studies have little or no consideration of the possible differential impact of both think-aloud methods on data provided by eye-tracking. Therefore, the main aim of this study is to compare and assess if and how these methods differ in terms of their impact on eye-tracking. The experiment was conducted for this purpose. Participants were 14 managers who played a specific simulation game with CTA use and 17 managers who played the same game with RTA use. The results empirically prove that CTA significantly distorts data provided by eye-tracking, whereas data gathered when RTA is used, provide independent pieces of evidence about the participants' behavior. These findings suggest that RTA is more suitable for combined use with eye-tracking for the purpose of the research of decision-making in the game environment.},
author = {Prokop, Michal and Pilař, Ladislav and Tich{\'{a}}, Ivana},
doi = {10.3390/s20102750},
file = {::},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Decision-making,Eye-tracking,Games,Simulation game,Think-aloud},
number = {10},
pages = {2750},
pmid = {32408507},
publisher = {MDPI AG},
title = {{Impact of think-aloud on eye-tracking: A comparison of concurrent and retrospective think-aloud for research on decision-making in the game environment}},
volume = {20},
year = {2020}
}
@inproceedings{Yamashita2018,
abstract = {There are two well-known difficulties to test and interpret methodologies for mining developer interaction traces: first, the lack of enough large datasets needed by mining or machine learning approaches to provide reliable results; and second, the lack of "ground truth" or empirical evidence that can be used to triangulate the results, or to verify their accuracy and correctness. Moreover, relying solely on interaction traces limits our ability to take into account contextual factors that can affect the applicability of mining techniques in other contexts, as well hinders our ability to fully understand the mechanics behind observed phenomena. The data presented in this paper attempts to alleviate these challenges by providing 600+ hours of developer interaction traces, from which 26+ hours are backed with video recordings of the IDE screen and developer's comments. This data set is relevant to researchers interested in investigating program comprehension, and those who are developing techniques for interaction traces analysis and mining.},
author = {Yamashita, Aiko and Petrillo, Fabio and Khomh, Foutse and Gu{\'{e}}h{\'{e}}neuc, Yann Ga{\"{e}}l},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1145/3196398.3196457},
isbn = {9781450357166},
issn = {02705257},
keywords = {empirical study,industrial data,interaction traces,log mining,program comprehension,programming flow},
month = {may},
pages = {50--53},
publisher = {IEEE Computer Society},
title = {{Developer interaction traces backed by IDE screen recordings from think aloud sessions}},
year = {2018}
}
@inproceedings{Salminen2019,
abstract = {Increased access to data and computational techniques enable innovations in the space of automated customer analytics, for example, automatic persona generation. Automatic persona generation is the process of creating data-driven representations from user or customer statistics. Even though automatic persona generation is technically possible and provides advantages compared to manual persona creation regarding the speed and freshness of the personas, it is not clear (a) what information to include in the persona profiles and (b) how to display that information. To query into these aspects relating information design of personas, we conducted a user study with 38 participants. In the findings, we report several challenges relating to the design of automatically generated persona profiles, including usability issues, perceptual issues, and issues relating to information content. Our research has implications for the information design of data-driven personas.},
author = {Salminen, Joni and Şeng{\"{u}}n, Sercan and Jung, Soon Gyo and Jansen, Bernard J.},
booktitle = {CHIIR 2019 - Proceedings of the 2019 Conference on Human Information Interaction and Retrieval},
doi = {10.1145/3295750.3298942},
isbn = {9781450360258},
keywords = {Automatically generated personas,Data-driven personas,Information design,Personas,User study},
month = {mar},
pages = {225--229},
publisher = {Association for Computing Machinery, Inc},
title = {{Design issues in automatically generated persona profiles: A qualitative analysis from 38 think-aloud transcripts}},
year = {2019}
}
@inproceedings{Johanssen2019,
abstract = {Thinking Aloud is a method that allows the collection of expressive user feedback for software improvement. However, its frequent application in a rapid development processes such as Continuous Software Engineering (CSE) is challenging, since repetitively performing manual observations and evaluations demand high effort. We propose the Continuous Thinking Aloud (CTA) approach for conducting Thinking Aloud during CSE. CTA records speech feedback for a user who starts using a new feature increment. The recordings are automatically transcribed and classified into one of four feedback categories that differentiate between insecure, neutral, positive, and negative sentiments. CTA visualizes these feedback classifications on a sentence level, next to its related high-level change of the feature increment. This supports developers in problem discovery, in particular regarding usability. CTA integrates with CSE processes and represents a scalable approach enabling repeated application during the software development lifecycle.},
author = {Johanssen, Jan Ole and Reimer, Lara Marie and Bruegge, Bernd},
booktitle = {Proceedings - 2019 IEEE/ACM Joint 4th International Workshop on Rapid Continuous Software Engineering and 1st International Workshop on Data-Driven Decisions, Experimentation and Evolution, RCoSE/DDrEE 2019},
doi = {10.1109/RCoSE/DDrEE.2019.00010},
isbn = {9781728122472},
keywords = {Classifier,Continuous software engineering,Feature crumb,Thinking aloud,Usability engineering,Visualization},
month = {may},
pages = {12--15},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Continuous thinking aloud}},
year = {2019}
}
@article{Fan2019,
abstract = {The concurrent think-aloud protocol-inwhich participants verbalize their thoughts when performing tasks- is a widely employed approach in usability testing. Despite its value, analyzing think-aloud sessions can be onerous because it often entails assessing all of a user's verbalizations. This has motivated previous research on developing categories to segment verbalizations into manageable units of analysis. However, the way in which a category might relate to usability problems is currently unclear. In this research, we sought to address this gap in our understanding. We also studied how speech features might relate to usability problems. Through two studies, this research demonstrates that certain patterns of verbalizations are more telling of usability problems than others and that these patterns are robust to different types of test products (i.e., physical devices and digital systems), access to different types of information (i.e., video and audio modality), and the presence or absence of a visualization of verbalizations. The implication is that the verbalization and speech patterns can potentially reduce the time and effort required for analysis by enabling evaluators to focus more on the important aspects of a user's verbalizations. The patterns could also potentially be used to inform the design of systems to automatically detect when in the recorded think-aloud sessions users experience problems.},
author = {Fan, Mingming and Lin, Jinglan and Chung, Christina and Truong, Khai N.},
doi = {10.1145/3325281},
issn = {15577325},
journal = {ACM Transactions on Computer-Human Interaction},
keywords = {Concurrent think-aloud,Loudness,Pitch,Sentiment,Silence,Speech features,Speech rate,Usability problems,Usability testing,Verbal fillers,Verbalization,Verbalization categories},
month = {jul},
number = {5},
pages = {28:1--28:35},
publisher = {Association for Computing Machinery},
title = {{Concurrent think-aloud verbalizations and usability problems}},
volume = {26},
year = {2019}
}
@article{Alhadreti2021,
abstract = {This paper presents the results of a study that aimed to compare the utility and validity of the traditional concurrent think-aloud and the co-discovery usability testing methods. The study was conducted in Saudi Arabia and involved three points of comparison: number and nature of usability problems discovered, test participants' experiences, and overall task performance. The results show significant differences between the two types of testing methods. The co-discovery method led to the detection of a greater number of minor usability problems relating to layout and functionality. The participants also found the co-discovery method to be easier and less tiring to perform and more natural for them than the concurrent think-aloud method. No difference was found between the methods in terms of participants' task performance. The study concludes that the co-discovery method seems to be appropriate for identifying numerous minor issues and ensuring that the usability testing experience is as natural as possible for participants. However, the classic method seems to be a more cost-effective method, as it is equally useful in revealing high-severity problems and requires only one participant per test session.},
author = {Alhadreti, Obead},
doi = {10.1080/10447318.2020.1809152},
issn = {15327590},
journal = {International Journal of Human-Computer Interaction},
number = {2},
pages = {118--130},
publisher = {Bellwether Publishing, Ltd.},
title = {{Comparing Two Methods of Usability Testing in Saudi Arabia: Concurrent Think-Aloud vs. Co-Discovery}},
volume = {37},
year = {2021}
}
@inproceedings{Meier2019,
abstract = {We describe our efforts to compare data collection methods using two think-aloud protocols in preparation to be used as a basis for automatic structuring and labeling of a large database of high-dimensional human activities data into a valuable resource for research in cognitive robotics. The envisioned dataset, currently in development, will contain synchronously recorded multimodal data, including audio, video, and biosignals (eye-tracking, motion-tracking, muscle and brain activity) from about 100 participants performing everyday activities while describing their task through use of think-aloud protocols. This paper provides details of our pilot recordings in the well-established and scalable “table setting scenario,” describes the concurrent and retrospective think-aloud protocols used, the methods used to analyze them, and compares their potential impact on the data collected as well as the automatic data segmentation and structuring process.},
author = {Meier, Moritz and Mason, Celeste and Putze, Felix and Schultz, Tanja},
booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
doi = {10.21437/Interspeech.2019-3072},
issn = {19909772},
keywords = {Activities of daily living,Biosignals,Cognitive robotics,Multimodal,Think-aloud},
pages = {559--563},
publisher = {International Speech Communication Association},
title = {{Comparative analysis of think-aloud methods for everyday activities in the context of cognitive robotics}},
volume = {2019-Septe},
year = {2019}
}
@article{Hinostroza2018,
abstract = {Many studies show that a large percentage of students lack the digital competencies to solve information problems using the internet. To address this problem, researchers have developed models to structure the process. However, we maintain that it is first necessary to understand how students actually search for information online when solving an information problem and compare their behaviours with the available literature. To do this, we collected and analysed the data on a laboratory setting of 41 students while they solved 16 information problems using the internet and expressed aloud what they were thinking whilst solving them. We identified 21 categories of actions, grouped into 9 activity types associated with four information search processes, showing that some of the students' stereotyped search behaviours are in fact conscious decisions based on the requirements of the task and the answers found. The results also show that searching for information on the internet can not only vary depending on the task's requirements, but also on the number of iterations students need to perform to reach an answer. These findings provide some evidence that challenge the assumption that students simply lack the competencies to search for information on the internet; rather, it seems that they show an awareness of different strategies, which they decide to use based on the context and purpose of the task, making their search behaviour more elaborated and complex than is usually portrayed by researchers in the field. Based on this, implications and further research lines are also discussed.},
author = {Hinostroza, J. Enrique and Ibieta, Andrea and Labb{\'{e}}, Christian and Soto, Mar{\'{i}}a Teresa},
doi = {10.1007/s10639-018-9698-2},
issn = {15737608},
journal = {Education and Information Technologies},
keywords = {Computer literacy,Digital competencies,Information problem-solving,Search strategies,Student internet search},
month = {sep},
number = {5},
pages = {1933--1953},
publisher = {Springer New York LLC},
title = {{Browsing the internet to solve information problems: A study of students' search actions and behaviours using a ‘think aloud' protocol}},
volume = {23},
year = {2018}
}
@article{Fan2020,
abstract = {Think-aloud protocols are a highly valued usability testing method for identifying usability problems. Despite the value of conducting think-aloud usability test sessions, analyzing think-aloud sessions is often time-consuming and labor-intensive. Consequently, previous research has urged the community to develop techniques to support fast-paced analysis. In this work, we took the first step to design and evaluate machine learning (ML) models to automatically detect usability problem encounters based on users' verbalization and speech features in think-aloud sessions. Inspired by recent research that shows subtle patterns in users' verbalizations and speech features tend to occur when they encounter problems, we examined whether these patterns can be utilized to improve the automatic detection of usability problems. We first conducted and recorded think-aloud sessions and then examined the effect of different input features, ML models, test products, and users on usability problem encounters detection. Our work uncovers several technical and user interface design challenges and sets a baseline for automating usability problem detection and integrating such automation into UX practitioners' workflow.},
author = {Fan, Mingming and Li, Yue and Truong, Khai N.},
doi = {10.1145/3385732},
issn = {21606463},
journal = {ACM Transactions on Interactive Intelligent Systems},
keywords = {AI-assisted UX analysis method,Think aloud,machine learning,speech features,usability problem,user experience (UX),verbalization},
month = {jun},
number = {2},
pages = {16:1--16:24},
publisher = {Association for Computing Machinery},
title = {{Automatic Detection of Usability Problem Encounters in Think-aloud Sessions}},
volume = {10},
year = {2020}
}
@article{Chen2018,
abstract = {The concurrent think-aloud protocol (CTA) is an effective method for collecting abundant product comments related to user satisfaction during the execution of evaluation tasks. However, manual analysis of these audio comments is time-consuming and labor-intensive. This paper aims to propose an approach for automated comprehensive evaluation of user interface (UI) satisfaction. It takes advantage of text mining and sentiment analysis (SA) techniques instead of manual analysis in order to assess user comments collected by the CTA. Based on the results of the SA, the proposed approach makes use of the analytic hierarchy process (AHP) method to evaluate the overall satisfaction and support developers for UI design improvements. In order to enhance the objectivity of evaluation, a sentiment matrix originating from text mining and SA on user comments is used to replace the criteria and the relative weights of the AHP method which were previously defined by experts. A comparison between the questionnaire survey method and the proposed approach in the empirical study suggested that the latter can efficiently evaluate UI satisfaction with high accuracy and provide designers abundant and specific information directly related to defects in design. It is argued that the proposed approach could be used as an automated framework for handling any type of comments.},
author = {Chen, Weipeng and Lin, Tao and Chen, Li and Yuan, Peisa},
doi = {10.1007/s10209-018-0610-z},
issn = {16155297},
journal = {Universal Access in the Information Society},
keywords = {Analytic hierarchy process,Concurrent think-aloud,Satisfaction evaluation,Sentiment analysis,Text mining},
month = {aug},
number = {3},
pages = {635--647},
publisher = {Springer Verlag},
title = {{Automated comprehensive evaluation approach for user interface satisfaction based on concurrent think-aloud method}},
volume = {17},
year = {2018}
}
@incollection{Johnson2017,
abstract = {CAD is a critical tool for engineers in the 21st century. To improve CAD usage and education, methods for assessing and evaluating modeling procedures and decision making are necessary. To this end, two common verbal data collection methods are assessed for analyzing CAD modeling procedures. Stimulated recall and concurrent think aloud are compared to each other and screen capture video data. While the concurrent think aloud method seems to increase the necessary modeling time, the think aloud requirement does not affect the proportion of time spent on particular activities. A novel method of using Cohens Kappa with time usage data was implemented to compare the audio methods to screen capture video data. Neither audio method showed significant agreement with the video data when corrected for chance agreement. It is likely that both video and audio data are required to observe significant insights with respect to CAD modeling procedures and decisions. Drawbacks and benefits associated with alternative methods are also highlighted.},
author = {Johnson, Michael D. and Ye, Karl},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-58071-5_24},
issn = {16113349},
keywords = {Design: analysis and design methods,Stimulated recall,Think aloud,UX and usability: evaluation methods and technique},
pages = {313--324},
publisher = {Springer Verlag},
title = {{An analysis of CAD modeling procedure data collection using synchronous and retrospective think aloud techniques}},
volume = {10271},
year = {2017}
}
